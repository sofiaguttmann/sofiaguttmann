---
title: "Prep2S24"
author: "Sofia Guttmann"
date: "2024-02-08"
format: pdf
editor: visual
---

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
library(mdsr)
library(nycflights13)
library(kableExtra)
```

Reminder: Prep assignments are to be completed individually. Upload a final copy of the .Qmd and renamed .pdf to your private repo, and submit the renamed pdf to Gradescope before Sunday, Feb. 11th at midnight (11:59 pm is what Gradescope shows).

# Reading

The associated reading for the week is Chapter 4, Chapter 5, Chapter 6 (skip 6.4) and Sections 8.3 and 8.4. This reading explores major functions in wrangling data, including reshaping data. There are many commands here to learn about - do your best to develop a sense of what they each do, and we will build on that by using them for the rest of the semester. You don't need to memorize them all.

Remember, I recommend you code along with the book examples. You can try out the code yourself - just be sure to load the mdsr package and any other packages referenced. You can get the code in R script files (basically, files of just R code, not like a .Rmd or .Qmd) from the book website.

\newpage

# 1 - Some basics

<!-- PROBLEM 1 ---------------------------------------------------------------->

Many different data wrangling commands are covered in these chapters. Identify the command you'd use for each of the operations below.

> part a - Add the average of 3 variables to the data set as a new variable.

Solution: You can use the **`mutate()`** function from the **`dplyr`** package

> part b - Keep only 4 columns of a data frame in a new data set.

Solution: You can use the **`select()`** function from the **`dplyr`** package

> part c - Choose observations that match a particular category of a categorical variable to keep in a new data set.

Solution: You can use the **`filter()`** function from the **`dplyr`** package

> part d - Combine two data sets based on common variables where all rows from the first are returned, along with any matches in the second.

Solution: You can use the **`left_join()`** function from the **`dplyr`** package

\newpage

<!-- PROBLEM 2 ---------------------------------------------------------------->

# 2 - NYC Flights

In Section 5.1, the `flights` and `airlines` tables within the `nycflights13` package are joined together.

> part a - Recreate the `flights_joined` dataset from Section 5.1, being sure to *glimpse* the data in the Console (or via the code chunk) to verify the join worked.

Solution:

```{r}

library(dplyr)
library(nycflights13)

flights_joined <- inner_join(flights, airlines, by = "carrier")

print(head(flights_joined))

```

> part b - Now, starting from `flights_joined`, create a new dataset `flights_short` that does the following:

-   creates a new variable, `distance_km`, which is distance in kilometers (note that 1 mile is about 1.6 kilometers)
-   keeps only the variables: `name`, `flight`, `arr_delay`, and `distance_km` and
-   keeps only observations where the distance is less than 480 kilometers (300 miles).

```{=html}
<!--
Hint: see examples in Section 4.1 for subsetting datasets and creating new variables.  
-->
```
Solution:

```{r}
flights_joined <- flights_joined %>%
  mutate(distance_km = distance * 1.6)  

flights_short <- flights_joined %>%
  select(name, flight, arr_delay, distance_km) %>%
  filter(distance_km < 480)

print(head(flights_short))


```

> part c - Using the functions introduced in Section 4.1.4, compute the number of flights (call this `N`), the average arrival delay (call this `avg_arr_delay`), and the average distance in kilometers (call this `avg_dist_km`) among these flights with distances less than 480 km (i.e. working off of `flights_short`), grouping by the carrier name. Sort the results in descending order based on `avg_arr_delay`. Save the results in a tibble object called `delay_summary`, and display the table.

```{=html}
<!--
Getting NAs for `avg_arr_delay`?  

You can drop all the cases that contain missing observations with the **tidyr** function `drop_na()` before grouping.
-->
```
Solution:

```{r}

library(dplyr)
library(tibble)


delay_summary <- flights_short %>%
  group_by(name) %>%
  summarize(N = n(),
            avg_arr_delay = mean(arr_delay, na.rm = TRUE),
            avg_dist_km = mean(distance_km, na.rm = TRUE)) %>%
  arrange(desc(avg_arr_delay))


print(delay_summary)


```

> part d - Rename the four columns in the `delay_summary` data table to `Airline`, `"Total flights under 480 km"`, `"Average arrival delay (mins)"` and `"Average distance (km)"`, respectively, then use `kable(booktabs = TRUE, digits = 0)` to make the final table output in the pdf close to publication quality.

```{=html}
<!--
Note: you can customize the number of digits by column by specifying a vector of digits, with any value for each non-numeric column. For example, see what happens when you specify the following for this example (or switch out for digits of your choosing to see how the output changes):

kable(booktabs = TRUE, digits = c(0, 0, 0, 1))

If you have issues with kable or kableExtra, do your best, and we can troubleshoot more in class.
-->
```
Solution:

```{r}

library(knitr)


names(delay_summary) <- c("Airline", "Total flights under 480 km", "Average arrival delay (mins)", "Average distance (km)")


kable(delay_summary, booktabs = TRUE, digits = 0)


```

```{=html}
<!-- 
Knit and commit, and probably push. If you haven't committed (or pushed) by now, you should have! Remember this is recommended for at the end of every problem, if not more often. 
-->
```
\newpage

<!-- PROBLEM 3 ---------------------------------------------------------------->

# 3 - Baby names - Variant of 6.2.5 example

> part a - Working with the `babynames` data in the **babynames** package, create a dataset `recent_names` that only includes years 2003 to 2017 (giving us the most recent 15 years of data).

<!-- This time you need to load the package. Remember we put these in our first chunk in our .Qmds, so you'll need to scroll up. -->

Solution:

```{r}

library(babynames)
library(dplyr)


recent_names <- babynames %>%
  filter(year >= 2003 & year <= 2017)

print(head(recent_names))

```

> part b - Following the code presented in Section 6.2.5, create a dataset called `recentnames_summary` that summarizes the total number of people in recent history (years 2003 to 2017) with each name, grouped by sex.

```{=html}
<!--
Hint: follow either code chunk at the start of Section 6.2.5, but don't filter on any particular names.

Take a look at the summarized dataset using `head()` or `View()` in the Console to verify your code works as expected.
-->
```
Solution:

```{r}

library(babynames)
library(dplyr)


recent_names <- babynames %>%
  filter(year >= 2003 & year <= 2017)

recentnames_summary <- recent_names %>%
  group_by(name, sex) %>%
  summarize(total_people = sum(n, na.rm = TRUE))

print(head(recentnames_summary))


```

> part c - Now, following the third and fourth code chunks presented in Section 6.2.5, reshape or *pivot* the summary data from *long* format to *wide* format. Only keep observations where more than 8,000 babies have been named in each sex (`M` and `F`), and find the smaller of the two ratios `M / F` and `F / M` to identify the top three sex-balanced names (and only the top three!). Save the wide data as `recentnames_balanced_wide`. Display the table.

```{=html}
<!--
Note: these names will likely be different from the ones found in the text since we limited the dataset to years 2003-2017 and names with greater than 8,000 individuals.)
-->
```
Solution:

```{r}

recentnames_summary_wide <- recentnames_summary %>%
  pivot_wider(names_from = sex, values_from = total_people)

recentnames_summary_wide_filtered <- recentnames_summary_wide %>%
  filter(M > 8000 & F > 8000)

recentnames_summary_wide_filtered <- recentnames_summary_wide_filtered %>%
  mutate(ratio_M_F = M / F,
         ratio_F_M = F / M)
 names
top_three_balanced_names <- recentnames_summary_wide_filtered %>%
  mutate(min_ratio = pmin(ratio_M_F, ratio_F_M)) %>%
  top_n(3, min_ratio)


recentnames_balanced_wide <- top_three_balanced_names


print(recentnames_balanced_wide)


```

> part d - Finally, use `pivot_longer()` to put the dataset back into *long* form. Call this dataset `recentnames_balanced` and display the table.

```{=html}
<!--
Hint: see Section 6.2.3. 
-->
```
Solution:

```{r}

recentnames_balanced <- recentnames_balanced_wide %>%
  pivot_longer(cols = c(M, F, ratio_M_F, ratio_F_M, min_ratio),
               names_to = "Variable",
               values_to = "Value")

print(recentnames_balanced)

```

\newpage

<!-- PROBLEM 4 ---------------------------------------------------------------->

# 4 - Ethics

Each subsection of Section 8.4 discusses an ethical scenario and ends with one or more questions. Consider the subsection 8.4.6 on "Reproducible spreadsheet analysis".

Write two or three sentences reflecting on how using RMarkdown would help avoid some of the issues described in this scenario, or at least make them easier to spot.

Solution: Using RMarkdown allows for reproducibility and transparency. Using one file ensures ease when tracking changes and transformations.

```{=html}
<!--
Knit, commit, and push, including the final renamed pdf, to your repo. Then, upload the .pdf to Gradescope before the deadline. 
-->
```
